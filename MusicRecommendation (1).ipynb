{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261ba07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_FOLDER is  C:\\Users\\rohan\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "import webbrowser\n",
    "import random\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "print(\"HOME_FOLDER is \",home)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a5174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playmusic(emotion):\n",
    "    happy = 'spotify:playlist:0iVQVFUV75bR3Tx8BxyQtb'\n",
    "    angry = 'spotify:playlist:0l9dAmBrUJLylii66JOsHB'\n",
    "    sad = 'spotify:playlist:69CSufUKurPlR6bGGvdfbH'\n",
    "    spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id='bd288506e28a4b91aac84363466f0b76', client_secret ='945d5853dcdd40fcafbe89a8fb010483',))\n",
    "    if(emotion == \"happy\" or emotion ==\"surprise\"):\n",
    "        a= 0\n",
    "        results = spotify.playlist_tracks(happy, fields=None, limit=100, offset=0, market=None, additional_types=('track', ))\n",
    "        s= []\n",
    "        for track in results['items']:\n",
    "            a = a+1\n",
    "        n = random.randint(0,a-1)\n",
    "        print(n)\n",
    "        for track in results['items'][: n]:\n",
    "            s= track\n",
    "        try:\n",
    "            webbrowser.open(s['track']['preview_url'])\n",
    "        except:\n",
    "            playmusic(emotion)\n",
    "    elif(emotion == \"sad\" or emotion ==\"neutral\" or emotion ==\"fear\"):\n",
    "        a= 0\n",
    "        results = spotify.playlist_tracks(sad, fields=None, limit=100, offset=0, market=None, additional_types=('track', ))\n",
    "        s= []\n",
    "        for track in results['items']:\n",
    "            a = a+1\n",
    "        n = random.randint(0,a-1)\n",
    "        print(n)\n",
    "        for track in results['items'][: n]:\n",
    "            s= track\n",
    "        try:\n",
    "            webbrowser.open(s['track']['preview_url'])\n",
    "        except:\n",
    "            playmusic(emotion)\n",
    "    elif(emotion == \"angry\" or emotion ==\"disgust\"):\n",
    "        a= 0\n",
    "        results = spotify.playlist_tracks(angry, fields=None, limit=100, offset=0, market=None, additional_types=('track', ))\n",
    "        s= []\n",
    "        for track in results['items']:\n",
    "            a = a+1\n",
    "        n = random.randint(0,a-1)\n",
    "        print(n)\n",
    "        for track in results['items'][: n]:\n",
    "            s= track\n",
    "        try:\n",
    "            webbrowser.open(s['track']['preview_url'])\n",
    "        except:\n",
    "            playmusic(emotion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69c5230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moodrecon():\n",
    "    try:\n",
    "        faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(\"Cannot Open Webcam\")\n",
    "        ret,frame = cap.read()\n",
    "        result = DeepFace.analyze(frame, actions = ['emotion'])\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "        cap.release()\n",
    "        emotion = result['dominant_emotion']\n",
    "    except:\n",
    "        emotion = '1'\n",
    "    print(emotion)\n",
    "    return emotion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b5a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechrecon():\n",
    "    try:\n",
    "        text_speech = pyttsx3.init()\n",
    "        answer = \"what is your mood\"\n",
    "        text_speech.say(answer)\n",
    "        text_speech.runAndWait()\n",
    "        r3 = sr.Recognizer()\n",
    "        r2 = sr.Recognizer()\n",
    "        text_speech = pyttsx3.init()\n",
    "        with sr.Microphone() as source:\n",
    "            print('Speak now ')\n",
    "            audio = r3.listen(source)\n",
    "        s = r2.recognize_google(audio)\n",
    "    except:\n",
    "        s = '1'\n",
    "    print(s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a5d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechrecon2():\n",
    "    try:\n",
    "        text_speech = pyttsx3.init()\n",
    "        answer = \"How would like to detect your mood\"\n",
    "        text_speech.say(answer)\n",
    "        text_speech.runAndWait()\n",
    "        r3 = sr.Recognizer()\n",
    "        r2 = sr.Recognizer()\n",
    "        text_speech = pyttsx3.init()\n",
    "        with sr.Microphone() as source:\n",
    "            print('Speak now ')\n",
    "            audio = r3.listen(source)\n",
    "        s = r2.recognize_google(audio)\n",
    "    except:\n",
    "        s = '1'\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d3fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015C9CC742F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't read cache at: .cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't write token to cache at: .cache\n",
      "Couldn't read cache at: .cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't write token to cache at: .cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "def choice():\n",
    "    s = 'face'\n",
    "    emo = '1'\n",
    "    #while(s == '1'):\n",
    "    #    s = speechrecon2()\n",
    "    #if(s=='speech'or s=='peach'):\n",
    "     #   while(emo == '1'):\n",
    "      #      emo = speechrecon()\n",
    "    if(s=='face'):\n",
    "        while(emo == '1'):\n",
    "            emo = moodrecon()\n",
    "    playmusic(emo)\n",
    "choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc9ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e353c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
